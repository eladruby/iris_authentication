# 住驻专转
import cv2
from tensorflow.keras import Model # type: ignore
from numpy.linalg import norm
import tensorflow as tf
import keras
import streamlit as st
from PIL import Image
import numpy as np
import os
import sys

#住祝 转 驻爪 专转 转  转拽转 砖爪转 砖转 转 专 专 砖转 转拽转 爪  砖  驻拽爪转
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))
# 驻拽爪转 转专 专 拽砖转转 拽抓 驻专
from src.segmentation.iris_img_normalization import IrisImgNormalization


#Triplet Loss爪专转 拽 专转  转 专拽专 砖  
class TripletLoss:
    #驻拽爪转  砖拽专转 拽专 爪专转 拽 拽
    def __init__(self):
        #专转  拽 砖 
        self.inp = tf.keras.Input(shape=(None, None, 3))

    #驻拽爪转 转 
    def embedding(self):

        #VGG16   拽爪 专 
        #include_top=False  砖驻拽爪 注  砖转 住  砖  住 拽专 砖
        #weights=None  砖  注 砖拽转 砖 专 驻   砖  转 注 -住 住驻爪驻 砖 转爪转 转 转专
        #input_tensor=self.inp  砖拽 砖   拽 砖专 注
        vgg16_fe = tf.keras.applications.VGG16(
            include_top=False, weights=None, input_tensor=self.inp
        )
        #专  砖砖 砖 砖   转 转转  (专拽 专注 砖 转 注 专注)
        vgg16_fe.trainable = False
        #Flatten  Dense 专   驻 砖 砖专 砖注专 转 砖转  Dense  砖拽 砖 注 爪专 砖   砖 专注 专 400 注 75  砖砖 砖转 
        #  转   专 砖 转  砖拽砖 专 注   转转 注专转 拽 爪专转 砖 拽  砖 砖 注
        # 砖转砖 砖转 拽爪 注 驻专 砖 1 注 1 砖 转砖  转 转转  注 转注专 注  驻拽住 转 注 砖转  转住  转
        #stride=1  砖砖 转注专 注  驻拽住 转  砖专
        #padding='same'  砖砖  转拽 转 转
        #activation='relu' 驻拽爪转 拽爪 砖 砖
        #name='out_conv' 转 砖 砖
        #砖 注爪 拽砖专  砖 驻 转   专 VGG16拽 专 拽 注 砖 专 转 砖  转  砖 专   
        out_conv = tf.keras.layers.Conv2D(
            filters=16, kernel_size=1, strides=1, padding='same',
            activation='relu', name='out_conv')(vgg16_fe.layers[-1].output)
        #转 专 驻爪转 砖 转 砖专 专拽 转 转转 专转 砖 MaxPooling 注砖 专 砖 拽转 (专), 砖转 
        out = tf.keras.layers.GlobalMaxPooling2D()(out_conv)
        #专转   砖
        #name='embedding' 转 砖 
        #转  转   注爪 专 砖  拽 转 专 转 转转 砖 embedding
        return Model(inputs=vgg16_fe.inputs, outputs=out, name='embedding')

#驻拽爪转 专 拽
def preprocess(uploaded_file, segmentation, model):
    #驻转转 转 砖注转 转 爪注转
    image = Image.open(uploaded_file).convert("RGB")
    #专 专爪 砖 转
    w_target = 400
    #专 专 砖 转 驻注
    w_orig, h_orig = image.size

    #注砖 专爪 驻 转 转 转 专 400 砖专 转 住 专 专 砖
    #砖 专 专爪 砖 转 驻 住 砖 转 拽专转
    h_target = int((w_target / w_orig) * h_orig)
    #拽转/转 转 专 专 专爪
    image_resized = image.resize((w_target, h_target))
    #注专转 转 驻拽爪转 转专 专 拽砖转转
    # 住 砖砖 爪专 住爪  爪专祝  住爪 驻拽爪  砖 转注 砖转砖 
    if segmentation:
        img = IrisImgNormalization(image_resized, model)
    else:
        #   驻拽爪 转驻注 专  住爪
        img = IrisImgNormalization(image_resized)
    #None   爪 拽砖转转 转  专 
    if img is None:
        return None
    
    #float32 驻转 转 注专 砖 驻拽住 住
    #爪驻 驻专  VGG16专 
    # 拽 转  注专 255  砖转 转 注 注专 注  0-1
    # 爪 注专    0-255 砖专  砖 Streamlit注砖 转  砖
    # 砖  注 注 注专  
    img = np.array(img).astype("float32") /255

    #  专 转 拽 砖  转 Batch  砖 住 转 转  爪专 住祝 
    img = np.expand_dims(img, axis=0)

    #  砖转  转  爪注 VGG16 砖 专 转   爪注    转 住   
    if img.ndim < 4:
        img = np.stack([img] * 3, axis=-1)

    return img
    



#专转 砖转 拽 专转 注  专驻 住 砖转  转 砖拽转
model_copy = TripletLoss()
#爪专转  注专转 驻拽爪 砖专 拽 砖 
embedding = model_copy.embedding()

# 转 拽 砖   砖 砖 注 转 砖拽转 转
embedding.build((75, 400, 3))

#专转 转 拽住抓 砖拽转 转 注
weights_path = os.path.join(os.path.dirname(__file__), "..", "..", "weights", "final.weights.h5")
#注转 拽 砖 砖拽转 转 注 
embedding.load_weights(weights_path)

#砖 注爪  注专 爪专转 砖拽 拽 驻砖 Streamlit爪专转 转专转 砖 
st.title("Iris Authentication System")

#爪专 砖转 注转  砖 注转 转 砖转 转转
col1, col2 = st.columns(2)

#爪专转 砖转 驻转专 注转 拽抓 砖 砖 注转 转 砖转 转转 砖  专爪 砖 转 专拽
#type=["jpg"] - jpg  砖 注转 专拽 拽爪 
#转转  驻转专 爪 转 砖  转专 拽砖转转 砖 转 转 砖 爪专 砖砖 住爪
#st.toggle - 转 注专  砖拽 注专 砖 砖
with col1:
    img_file1 = st.file_uploader("Upload Image 1 jpg file only*", type=["jpg"])
    seg1 = st.toggle("Use segmentation for Image 1")

with col2:
    img_file2 = st.file_uploader("Upload Image 2 jpg file only*", type=["jpg"])
    seg2 = st.toggle("Use segmentation for Image 2")


#拽  注 转 砖转 转转  砖专拽  转 砖 专拽
if img_file1 and img_file2:

    # 驻转 转 转转 砖 爪专 住爪   转  住爪 
    if seg1 or seg2:
        #爪专转 转  拽抓  住爪
        MODEL_PATH = os.path.join(os.path.dirname(__file__), "..", "..", "models", "segmentation_model.keras")
        #专 爪 注    爪专  专爪 注 转 拽抓   拽 砖  注 专住 砖 拽爪  专 住 砖
        keras.config.enable_unsafe_deserialization()
        #keras 注转  注专转 住驻专转 注转  砖 
        model = keras.models.load_model(MODEL_PATH, compile=False)

    #注专转 砖转 转转 驻拽爪转 专 砖爪专 注转
    img1 = preprocess(img_file1, seg1, model if seg1 else None)
    img2 = preprocess(img_file2, seg2, model if seg2 else None)

    #专  爪 拽砖转转  专 砖 None  驻转 转 转转 专
    if img1 is None or img2 is None:
        st.error("Could not find iris")
    else:
        #   爪 转 砖转 转转 专 专
        #st.image - 爪 转 转转
        #caption - 转 砖  转
        #width - 拽注 转 专 砖 转
        st.image([img1.squeeze(), img2.squeeze()],
                 caption=["Image 1", "Image 2"], width=150)

        #住转 转转   爪 转 拽专 转转 砖
        embedding1 = embedding.predict(img1)
        embedding2 = embedding.predict(img2)
        #砖 专拽  拽专 砖 砖转 转转
        #norm -  拽  注专 注专  住专 转 砖, 转 转爪  注 专注, 转 住  专注 砖  转爪转  砖 转 砖专砖  砖 专拽 拽
        distance = norm(embedding1 - embedding2)

        #转转 专拽  砖转 转转
        st.write(" **Distance between embeddings:**", distance)
        #拽注转 注专 拽住 专拽 砖 砖转 转转 砖砖转 转 专   砖注 砖 注 砖转
        #拽注转 转 专拽 驻 住 注
        threshold = 1.0
        #拽  专拽 转转 拽 专拽 拽住
        if distance < threshold:
            #    转
            st.success("Authentication Successful")
        else:
            #    砖转
            st.warning("Authentication Failed")
